<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Ridge regression</title>

  <!-- MathJax Config -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
  </script>

  <!-- MathJax Scripts -->
  <script type="text/javascript" async
    src="https://polyfill.io/v3/polyfill.min.js?features=es6">
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Ridge regression | Pieter-Jan</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Ridge regression" />
<meta name="author" content="piinghel" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In the last article, we saw how a simple low-volatility ranking strategy delivered solid returns. By scaling returns based on volatility, we could improve performance with minimal complexity. But what if we could do better?" />
<meta property="og:description" content="In the last article, we saw how a simple low-volatility ranking strategy delivered solid returns. By scaling returns based on volatility, we could improve performance with minimal complexity. But what if we could do better?" />
<link rel="canonical" href="http://localhost:4000/quants/2025/02/09/ridge.html" />
<meta property="og:url" content="http://localhost:4000/quants/2025/02/09/ridge.html" />
<meta property="og:site_name" content="Pieter-Jan" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-02-09T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Ridge regression" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"piinghel"},"dateModified":"2025-02-09T00:00:00+01:00","datePublished":"2025-02-09T00:00:00+01:00","description":"In the last article, we saw how a simple low-volatility ranking strategy delivered solid returns. By scaling returns based on volatility, we could improve performance with minimal complexity. But what if we could do better?","headline":"Ridge regression","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/quants/2025/02/09/ridge.html"},"url":"http://localhost:4000/quants/2025/02/09/ridge.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Pieter-Jan" />
</head>
</head>

<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Pieter-Jan</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
    <div class="wrapper">
      <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Ridge regression</h1>
    <p class="post-meta"><time class="dt-published" datetime="2025-02-09T00:00:00+01:00" itemprop="datePublished">
        Feb 9, 2025
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><a href="https://piinghel.github.io/quant/2024/12/15/low-volatility-factor.html">In the last article</a>, we saw how a simple <strong>low-volatility ranking strategy</strong> delivered solid returns. By scaling returns based on volatility, we could improve performance with minimal complexity. But what if we could do better?</p>

<p>Rather than relying on a single heuristic, why not let the data determine the optimal ranking function? That’s exactly what we’ll do here—<strong>combine multiple features</strong> and use <strong>a linear regression model</strong> to rank stocks based on expected performance.</p>

<p>Stock selection isn’t straightforward. We deal with <strong>price changes, trading volume, and risk levels</strong>, all measured on different scales. Without proper normalization, large features like market cap will overshadow smaller ones like short-term returns. In the previous approach, we used a <strong>single low-volatility rule</strong> to rank stocks, which worked well. This time, we’ll refine the process by using <strong>multiple linear regression</strong> to integrate several predictive signals into one model.</p>

<p>The dataset remains the same—<strong>daily price, volume, and market capitalization data</strong> for all <strong>Russell 1000</strong> constituents, covering <strong>3,300 stocks historically</strong>. Since the investable universe changes over time, we apply basic liquidity filters, excluding stocks priced below <strong>$5</strong> to ensure realistic implementation.</p>

<h2 id="feature-engineering">Feature Engineering</h2>

<p>A key advantage of using a regression model is that it learns how to combine features on its own. Since we’re using <strong>linear regression</strong>, we’re assuming all relationships are <strong>linear</strong>—no interaction terms for now.</p>

<p>Obviously, we need to define our predictive features and choose a target variable. We focus on <strong>price, volume, market capitalization, and market-derived features</strong>. Below is a breakdown of the main feature groups, computed daily for all <strong>3,300 stocks</strong> in our universe.</p>

<ol>
  <li><strong>Momentum Features</strong>
    <ul>
      <li>Capture trend-following behavior.</li>
      <li>Examples:
        <ul>
          <li>Lagged returns over 1 to 10 days.</li>
          <li>Rolling cumulative returns over 21 to 252 days.</li>
          <li>Moving Average Convergence Divergence (MACD) to detect shifts in momentum.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Volatility Features</strong>
    <ul>
      <li>Measure risk.</li>
      <li>Examples:
        <ul>
          <li>Rolling historical volatility over 21, 63, or 126 days.</li>
          <li>Separate downside and upside volatility.</li>
          <li>Average True Range (ATR) to normalize price fluctuations.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Liquidity Features</strong>
    <ul>
      <li>Assess trading activity.</li>
      <li>Examples:
        <ul>
          <li>Rolling mean and standard deviation of trading volume.</li>
          <li>Ratio of current volume to its rolling maximum to highlight unusual trading activity.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Size Features</strong>
    <ul>
      <li>Measure company scale.</li>
      <li>Examples:
        <ul>
          <li>Rolling mean and minimum of market cap.</li>
          <li>Distinguishes small-cap from large-cap stocks.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Short Mean Reversion Features</strong>
    <ul>
      <li>Identify when prices revert to historical norms.</li>
      <li>Examples:
        <ul>
          <li>Price deviation from its rolling moving average.</li>
          <li>Position relative to rolling minimum and maximum values.</li>
          <li>Bollinger Bands to spot overbought or oversold conditions.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Correlation with the Market</strong>
    <ul>
      <li>Capture systematic risk.</li>
      <li>Examples:
        <ul>
          <li>Rolling correlation with the Russell 1000 over 63-day windows.</li>
          <li>Helps separate defensive stocks from high-beta names.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>That leaves us with <strong>around 150 predictive features</strong>, some of which are obviously correlated.</p>

<h3 id="target-variable">Target Variable</h3>
<p>Now, what exactly are we trying to predict? We’ll focus on two targets:</p>

<ul>
  <li><strong>Return over the next 20 days</strong></li>
  <li><strong>Sharpe ratio over the next 20 days</strong></li>
</ul>

<p>Could we explore other horizons? Sure. But to keep things simple, we’ll stick to <strong>20 days</strong> for now.</p>

<h2 id="preprocessing-normalizing-the-data">Preprocessing: Normalizing the Data</h2>

<p>Stock features come in all shapes and sizes. Some, like market cap, have values in the billions, while others, like daily returns, are tiny. <strong>The model will still work without normalization</strong>, but features on vastly different scales might lead to <strong>weird or unintended rankings</strong>.</p>

<p>The intuition is simple: putting everything on a similar scale <strong>should</strong> improve ranking consistency. But is that actually true? That’s what we’re testing here.</p>

<p>To do this, we apply <strong>cross-sectional normalization</strong>, meaning we adjust each feature <strong>relative to all other stocks on the same day</strong>. That way, the model focuses on <strong>relative differences</strong> rather than raw values.</p>

<p>For a given feature $X$, the normalized value for stock $i$ on time $t$ is:</p>

\[X^{\text{norm}}_{i,t} = f(X_{i,t}, X_{1:N,t})\]

<p>where:</p>
<ul>
  <li>$X_{i,t}$ is the raw feature value for stock $i$ at time $t$.</li>
  <li>$X_{1:N,t}$ is the set of values for all stocks on time $t$.</li>
  <li>$f(\cdot)$ is the chosen normalization method.</li>
</ul>

<p>There are a few ways to do this:</p>

<h4 id="1-z-scoring"><strong>1. Z-Scoring</strong></h4>
<p>Z-scoring transforms values so they have a <strong>mean of 0</strong> and a <strong>standard deviation of 1</strong>:</p>

\[X^{\text{norm}}_{i,t} = \frac{X_{i,t} - \mu_t}{\sigma_t}\]

<p>where:</p>
<ul>
  <li>
    <p>$\mu_t$ is the mean across all stocks on day $t$:</p>

\[\mu_t = \frac{1}{N} \sum_{i=1}^{N} X_{i,t}\]
  </li>
  <li>
    <p>$\sigma_t$ is the standard deviation:</p>

\[\sigma_t = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (X_{i,t} - \mu_t)^2}\]
  </li>
</ul>

<p>To prevent extreme values from distorting results, we clip any outliers beyond <strong>±5 standard deviations</strong>.</p>

<h4 id="2-ranking-normalization"><strong>2. Ranking Normalization</strong></h4>
<p>Instead of working with raw values, we <strong>rank stocks</strong> and scale the ranks between <strong>0 and 1</strong>:</p>

\[R_{i,t} = \frac{r_{i,t}}{N}\]

<p>where:</p>
<ul>
  <li>$r_{i,t}$ is the rank of stock $i$ at time $t$ (1 for the lowest value, $N$ for the highest).</li>
  <li>$R_{i,t}$ is the normalized rank.</li>
</ul>

<p>This method is <strong>less sensitive to extreme values</strong> and works well for features with skewed distributions.</p>

<h3 id="does-normalization-actually-help"><strong>Does Normalization Actually Help?</strong></h3>

<p>The model doesn’t <strong>need</strong> normalization to work—it will still produce rankings using raw features. But does normalization lead to <strong>better</strong> rankings? That’s what we’re testing.</p>

<p>We compare four approaches:</p>

<ol>
  <li><strong>No Normalization (Raw Features)</strong> – A baseline.</li>
  <li><strong>Z-Scoring (Global)</strong> – Standardizes each feature across all stocks.</li>
  <li><strong>Ranking (Global)</strong> – Maps feature values to a uniform scale.</li>
  <li><strong>Sector-Specific Normalization</strong> – Normalizes features <strong>within each sector</strong> instead of across the entire market.</li>
</ol>

<h3 id="why-this-matters">Why This Matters</h3>

<p>Without normalization, features like <strong>market cap</strong> might completely overshadow others like <strong>short-term returns</strong>. The question is whether that distorts the model’s ability to rank stocks effectively.</p>

<p>Below, in <strong>Figure 1</strong>, we show how different normalization methods affect a single feature (20-day return). From left to right: the original distribution, Z-scored, and ranked.</p>

<p><img src="/assets/ridge/example_normalization.png" alt="Figure 1" /></p>

<p><strong>Figure 1</strong>: Effect of Normalization on 20-Day Return Distribution. Left: Original data, Middle: Z-scored, Right: Ranked between 0 and 1.</p>

<h3 id="handling-missing-data">Handling Missing Data</h3>

<p>Stock data isn’t always perfect—sometimes values are missing. The model can still run without them, but leaving gaps in the data isn’t ideal. So how do we fill them in?</p>

<p>We keep it simple:</p>

<ul>
  <li><strong>Forward fill:</strong> If a stock has prior data, we use the last known value.</li>
  <li><strong>Cross-sectional mean imputation:</strong> If no past data exists, we replace the missing value with the <strong>sector average</strong> for that day.</li>
  <li><strong>Default values:</strong> If neither of the above works, we apply:
    <ul>
      <li><strong>Z-scoring:</strong> Missing values are set to <code class="language-plaintext highlighter-rouge">0</code>.</li>
      <li><strong>Ranking:</strong> Missing values are set to <code class="language-plaintext highlighter-rouge">0.5</code> (midpoint of the ranking scale).</li>
    </ul>
  </li>
</ul>

<p>Could we get more sophisticated? Absolutely. There are plenty of ways to handle missing data, from advanced statistical methods to ML-based imputations. But for now, we’re sticking with a <strong>simple, reliable approach</strong>.</p>

<p>A deeper dive into missing data strategies is a topic for another time.</p>

<h2 id="modeling-the-ranking-score">Modeling the Ranking Score</h2>

<p>At the core of this strategy is a model that predicts a stock’s <strong>ranking score</strong>—which could be its <strong>Sharpe ratio, return, or any other performance measure</strong>.</p>

<p>We frame this as a <strong>prediction problem</strong>:</p>

\[s_{i,t+1} = \mathbb{E}_t[s_{i,t+1}] + \epsilon_{i,t+1}\]

<p>where:</p>
<ul>
  <li>$s_{i,t+1}$ is the <strong>true ranking score</strong> for stock $i$ at time $t+1$.</li>
  <li>$\mathbb{E}<em>t[s</em>{i,t+1}]$ is the <strong>model’s expected ranking score</strong> given available information at time $t$.</li>
  <li>$\epsilon_{i,t+1}$ is the <strong>error term</strong>—things the model can’t predict.</li>
</ul>

<p>The goal is to model:</p>

\[\mathbb{E}_t[s_{i,t+1}] = g(\mathbf{z}_{i,t})\]

<p>where:</p>
<ul>
  <li>$\mathbf{z}_{i,t}$ is a vector of predictor variables for stock $i$ at time $t$.</li>
  <li>$g(\cdot)$ is a function mapping predictors to ranking scores.</li>
</ul>

<p>This function $g(\cdot)$ follows two key rules:</p>

<ol>
  <li><strong>It’s consistent across stocks and time.</strong>
    <ul>
      <li>The same function applies to every stock and every time period.</li>
      <li>This ensures stable and comparable rankings across the dataset.</li>
    </ul>
  </li>
  <li><strong>It only depends on the features $\mathbf{z}_{i,t}$.</strong>
    <ul>
      <li>The model only considers a stock’s own characteristics at time $t$.</li>
      <li>No direct dependencies on past predictions or other stocks.</li>
    </ul>
  </li>
</ol>

<h3 id="why-ridge-regression">Why Ridge Regression?</h3>

<p>We approximate $g(\cdot)$ using <strong>Ridge Regression</strong>, a linear model that works well when predictors are highly correlated.</p>

<p>What makes Ridge a good fit?</p>

<ul>
  <li><strong>Handles multicollinearity</strong> – Stocks with similar characteristics tend to move together. Ridge prevents unstable coefficients.</li>
  <li><strong>Adds an $L_2$ penalty</strong> – Shrinks large coefficients, reducing overfitting and improving generalization.</li>
  <li><strong>Balances bias and variance</strong> – Helps the model stay stable across different time periods.</li>
</ul>

<p>The loss function for Ridge Regression is:</p>

\[\text{Minimize: } \frac{1}{n} \sum_{i=1}^n (y_i - \mathbf{x}_i^\top \boldsymbol{\beta})^2 + \lambda \sum_{j=1}^p \beta_j^2\]

<p>The second term ($\lambda \sum_{j=1}^p \beta_j^2$) <strong>penalizes large coefficients</strong>, keeping things smooth and stable.</p>

<p>With the model set up, the next step is <strong>validation</strong>—training Ridge Regression on historical data and evaluating its ability to rank stocks effectively.</p>

<h2 id="expanding-walkforward-validation">Expanding Walkforward Validation</h2>

<p>To evaluate the model, we use an <strong>expanding walkforward validation procedure</strong>. It works like this:</p>

<ol>
  <li><strong>Start with a 3-year burn-in period</strong> – The model isn’t tested yet; it just learns from the data.</li>
  <li><strong>Update the model every 2 years</strong> – Each update incorporates all available data up to that point.</li>
  <li><strong>Keep expanding the dataset</strong> – Older data stays in, while new data gets added.</li>
</ol>

<p>This approach ensures the model <strong>keeps learning from new market conditions</strong> while retaining long-term patterns.</p>

<p>Why not use a <strong>rolling validation window</strong>? Because it <strong>only keeps recent data</strong>, discarding older information that could still be useful. In my experience, an <strong>expanding</strong> window works better because it helps the model recognize long-term relationships, leading to more stable predictions.</p>

<p>For hyperparameter tuning, you can <strong>split each training period into train and validation sets</strong>. It’s not always necessary, but it helps fine-tune parameters before making predictions.</p>

<p>Below is a <strong>schematic of the expanding walkforward approach</strong>:</p>

<p><img src="/assets/ridge/walk-forward.png" alt="Figure 2" /></p>

<p><strong>Figure 2</strong>: Expanding walkforward validation process.</p>

<h2 id="portfolio-construction">Portfolio Construction</h2>

<p>Once we have stock rankings, we <strong>build a long-short portfolio</strong>:</p>

<ul>
  <li><strong>Go long</strong> on the top 75 ranked stocks.</li>
  <li><strong>Short</strong> the bottom 75 ranked stocks.</li>
</ul>

<p>Would different numbers (e.g., 50, 100, 150) change the outcome? Not really—the approach is robust across portfolio sizes.</p>

<p>To balance risk, we apply <strong>volatility targeting</strong>. This means:</p>
<ul>
  <li><strong>Higher-volatility stocks get lower weights.</strong></li>
  <li><strong>Lower-volatility stocks get higher weights.</strong></li>
</ul>

<p>This ensures the portfolio maintains a <strong>consistent risk profile</strong>, rather than being dominated by volatile stocks.</p>

<p>By combining <strong>data-driven rankings</strong> with <strong>risk-aware position sizing</strong>, we get a <strong>well-diversified portfolio</strong> that dynamically adjusts over time.</p>

<h2 id="results">Results</h2>

<p>To compare different modeling choices, we plot the <strong>cumulative returns of all strategies</strong>, scaled to <strong>8% volatility</strong> (Figure 3). This ensures a fair comparison by normalizing risk across models.</p>

<p>We evaluate <strong>10 different model variations</strong>, combining:</p>
<ul>
  <li><strong>5 normalization methods</strong>: Raw, Z-score (global &amp; sector), Ranking (global &amp; sector).</li>
  <li><strong>2 target labels</strong>: Sharpe Ratio (SR 20) and Return (Return 20).</li>
  <li><strong>A combined strategy (“Combo”)</strong>, which equally weights all strategies.</li>
</ul>

<p>For now, Figure 3 remains unlabeled—but what’s clear is that some strategies perform significantly better than others.</p>

<p><img src="/assets/ridge/all_lines.png" alt="Figure 3" /></p>

<p><strong>Figure 3</strong>: Performance comparison of different modeling choices, all scaled to 8% volatility.</p>

<h2 id="the-biggest-impact-comes-from-the-target-label">The biggest impact comes from the target label</h2>

<p>Figure 4 breaks down performance across three key dimensions:</p>
<ul>
  <li><strong>Target label</strong>: Are models trained on <strong>Sharpe Ratio</strong> more effective than those trained on <strong>raw returns</strong>?</li>
  <li><strong>Sector-based normalization</strong>: Does normalizing within industries improve stock rankings?</li>
  <li><strong>Normalization method</strong>: Does ranking or Z-scoring help relative to using raw features?</li>
</ul>

<p><img src="/assets/ridge/summary_barplot.png" alt="Figure 4" /></p>

<p><strong>Figure 4</strong>: Sharpe Ratio performance across key modeling choices.</p>

<p>The results are <strong>not what we might have expected</strong>.</p>

<ul>
  <li><strong>The most important factor is the target label</strong>—models trained on <strong>Sharpe Ratio significantly outperform those trained on raw returns</strong>. This suggests that risk-adjusted rankings provide more stable predictive signals.</li>
  <li><strong>Sector-based normalization improves performance</strong>, but to a lesser degree. It still provides a clear benefit over global normalization, reinforcing that stocks should be compared within their peer groups.</li>
  <li><strong>Surprisingly, the choice of normalization method (ranking or Z-scoring) doesn’t make a huge difference</strong>. We expected standardization to matter more, but raw features perform nearly as well, suggesting that the model is already capturing key relationships.</li>
</ul>

<p>While this gives a high-level overview, Figure 5 dives deeper into <strong>why the target label interacts with normalization choices in unexpected ways</strong>.</p>

<h2 id="normalization-effects-depend-on-the-target-label">Normalization effects depend on the target label</h2>

<p>Figure 5 examines <strong>how normalization impacts performance depending on whether the model is trained on Sharpe Ratio or raw returns</strong>.</p>

<p><img src="/assets/ridge/normalization_target.png" alt="Figure 5" /></p>

<p><strong>Figure 5</strong>: Cumulative return of different normalization methods, conditioned on the target label.</p>

<ul>
  <li><strong>For Sharpe Ratio (right panel), both ranking and Z-scoring perform well.</strong>
    <ul>
      <li>Sharpe Ratio already accounts for risk, so standardizing features helps extract meaningful signals.</li>
      <li>Raw (unprocessed) features lag behind, as expected.</li>
    </ul>
  </li>
  <li><strong>For Return (left panel), normalization makes a much bigger difference.</strong>
    <ul>
      <li>Ranking is the best choice, while Z-scoring surprisingly <strong>performs worse than raw features</strong>.</li>
      <li>This suggests that return-based training is <strong>more sensitive to normalization artifacts</strong>, possibly because extreme values distort the model.</li>
    </ul>
  </li>
</ul>

<p>The takeaway: <strong>target label is the primary driver of differences, followed by sector normalization, while normalization type itself has surprisingly little impact</strong>.</p>

<h2 id="the-combo-strategy-performs-surprisingly-well">The “Combo” strategy performs surprisingly well</h2>

<p>One unexpected finding is that the <strong>“Combo” strategy</strong>, which equally weights all models, performs almost as well as the best individual model.</p>

<ul>
  <li>Despite not being optimized for a single approach, <strong>blending multiple signals leads to robust performance.</strong></li>
  <li>The Combo strategy ranks <strong>second overall in terms of Sharpe Ratio</strong>, highlighting the benefits of diversification.</li>
</ul>

<p>Instead of searching for a single “best” normalization method, this suggests that <strong>combining multiple perspectives can be a stronger approach</strong>.</p>

<h2 id="full-performance-breakdown">Full performance breakdown</h2>

<p>To quantify these findings, Table 1 presents a full breakdown of returns, volatility, and Sharpe Ratios across all models.</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Return (ann. %)</th>
      <th>Volatility (ann. %)</th>
      <th>Sharpe Ratio (ann.)</th>
      <th>Maximum Drawdown (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SR Zscore By Sector</td>
      <td>10.8</td>
      <td>8.1</td>
      <td>1.3</td>
      <td>12.6</td>
    </tr>
    <tr>
      <td>Combo</td>
      <td>8.4</td>
      <td>6.7</td>
      <td>1.3</td>
      <td>13.4</td>
    </tr>
    <tr>
      <td>SR Ranking By Sector</td>
      <td>9.8</td>
      <td>8.0</td>
      <td>1.2</td>
      <td>12.9</td>
    </tr>
    <tr>
      <td>SR Zscore Globally</td>
      <td>10.1</td>
      <td>8.6</td>
      <td>1.2</td>
      <td>19.0</td>
    </tr>
    <tr>
      <td>SR Ranking Globally</td>
      <td>9.3</td>
      <td>8.5</td>
      <td>1.1</td>
      <td>16.9</td>
    </tr>
    <tr>
      <td>SR Raw Globally</td>
      <td>8.9</td>
      <td>8.5</td>
      <td>1.1</td>
      <td>16.1</td>
    </tr>
    <tr>
      <td>Return Ranking By Sector</td>
      <td>7.6</td>
      <td>7.6</td>
      <td>1.0</td>
      <td>14.9</td>
    </tr>
    <tr>
      <td>Return Raw Globally</td>
      <td>7.2</td>
      <td>7.3</td>
      <td>1.0</td>
      <td>16.7</td>
    </tr>
    <tr>
      <td>Return Ranking Globally</td>
      <td>7.5</td>
      <td>7.7</td>
      <td>1.0</td>
      <td>18.4</td>
    </tr>
    <tr>
      <td>Return Zscore By Sector</td>
      <td>6.6</td>
      <td>7.4</td>
      <td>0.9</td>
      <td>20.1</td>
    </tr>
    <tr>
      <td>Return Zscore Globally</td>
      <td>5.5</td>
      <td>7.5</td>
      <td>0.7</td>
      <td>21.0</td>
    </tr>
  </tbody>
</table>

<p><strong>Table 1</strong>: Performance metrics across different modeling choices, ranked by Sharpe Ratio. Results exclude transaction costs and slippage.</p>

<h2 id="final-thoughts">Final thoughts</h2>

<ul>
  <li><strong>The biggest driver of performance is the target label.</strong> Training on <strong>Sharpe Ratio</strong> leads to significantly better results than training on returns.</li>
  <li><strong>Sector-based normalization improves rankings.</strong> Normalization stocks within their industry provides more stable and accurate signals than global normalization.</li>
  <li>Normalization method (<strong>ranking vs. Z-scoring</strong>) has <strong>less impact than expected</strong>. Raw features perform nearly as well, suggesting the model already captures key relationships.</li>
  <li>The <strong>“Combo” strategy performs surprisingly well</strong>, ranking second overall. Diversifying across different approaches stabilizes performance.</li>
  <li>Instead of searching for a single “best” model, <strong>combining multiple perspectives provides a more robust and stable approach.</strong></li>
</ul>

<p>The key takeaway? <strong>The target label matters most, followed by sector-based normalization. Normalization method itself is less critical than expected.</strong></p>

<h2 id="todo">TODO</h2>
<ul>
  <li>results be a bit more in detail about the performance; talk also about the combo</li>
  <li>Maybe add the normaliation a bit more clear with a fomula</li>
  <li>Conclude</li>
  <li>Feature engineering is a bit weird with already speaking about the model without having introducted the model</li>
</ul>

  </div><a class="u-url" href="/quants/2025/02/09/ridge.html" hidden></a>
</article>

    </div>
  </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="http://localhost:4000/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">piinghel</li>
          <li><a class="u-email" href="mailto:pjinghelbrecht@gmail.com">pjinghelbrecht@gmail.com</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p>Systematic trading and data science things.
</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
